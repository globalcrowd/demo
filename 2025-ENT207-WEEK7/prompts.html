<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Workshop Prompt Guide</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            line-height: 1.6;
            color: #333;
            background: #f5f7fa;
            padding: 20px;
        }
        
        .container {
            max-width: 900px;
            margin: 0 auto;
            background: white;
            padding: 40px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        
        h1 {
            color: #667eea;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
            margin-bottom: 20px;
        }
        
        h2 {
            color: #764ba2;
            margin-top: 40px;
            margin-bottom: 15px;
            padding-bottom: 8px;
            border-bottom: 2px solid #f0f0f0;
        }
        
        h3 {
            color: #555;
            margin-top: 25px;
            margin-bottom: 10px;
        }
        
        h4 {
            color: #666;
            margin-top: 20px;
            margin-bottom: 8px;
        }
        
        p {
            margin-bottom: 15px;
        }
        
        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            font-size: 0.9em;
            color: #d63384;
        }
        
        pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 15px 0;
        }
        
        pre code {
            background: none;
            color: #f8f8f2;
            padding: 0;
        }
        
        ul, ol {
            margin-left: 30px;
            margin-bottom: 15px;
        }
        
        li {
            margin-bottom: 8px;
        }
        
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
        }
        
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        
        th {
            background: #667eea;
            color: white;
        }
        
        tr:nth-child(even) {
            background: #f9f9f9;
        }
        
        blockquote {
            border-left: 4px solid #667eea;
            padding-left: 20px;
            margin: 20px 0;
            color: #666;
            font-style: italic;
        }
        
        a {
            color: #667eea;
            text-decoration: none;
        }
        
        a:hover {
            text-decoration: underline;
        }
        
        .back-button {
            display: inline-block;
            margin-bottom: 20px;
            padding: 10px 20px;
            background: #667eea;
            color: white;
            border-radius: 5px;
            text-decoration: none;
            font-weight: 600;
        }
        
        .back-button:hover {
            background: #5568d3;
            text-decoration: none;
        }
        
        hr {
            border: none;
            border-top: 2px solid #e0e0e0;
            margin: 40px 0;
        }
    </style>
</head>
<body>
    <div class="container">
        <a href="index.html" class="back-button">‚Üê Back to Workshop Home</a>
        <h1 id="ai-image-analysis-workshop-prompt-guide-for-students">AI Image Analysis Workshop: Prompt Guide for Students</h1>
<h2 id="week-7-advanced-features-workshop">Week 7 - Advanced Features Workshop</h2>
<hr />
<h2 id="table-of-contents">üìö Table of Contents</h2>
<ol>
<li><a href="#understanding-prompts">Understanding Prompts</a></li>
<li><a href="#choosing-your-ai-coding-assistant">Choosing Your AI Coding Assistant</a></li>
<li><a href="#main-prompt">Main Prompt: Creating the Django App</a></li>
<li><a href="#system-prompt">System Prompt: Image Analysis Instructions</a></li>
<li><a href="#iteration-prompts">Iteration Prompts: Adding Features</a></li>
<li><a href="#debugging-prompts">Debugging Prompts</a></li>
<li><a href="#api-specific-notes">API-Specific Notes</a></li>
</ol>
<hr />
<h2 id="understanding-prompts">üéØ Understanding Prompts</h2>
<h3 id="what-is-a-prompt">What is a Prompt?</h3>
<p>A prompt is a set of instructions you give to an AI coding assistant (like Qwen Coder, Claude Code, GitHub Copilot, or others) to tell it exactly what you want it to do. Think of it like giving instructions to a very talented but literal assistant.</p>
<h3 id="why-prompts-matter">Why Prompts Matter</h3>
<ul>
<li><strong>Good prompts</strong> = AI builds exactly what you need, first try</li>
<li><strong>Vague prompts</strong> = AI guesses and might build the wrong thing</li>
<li><strong>Detailed prompts</strong> = Faster development, fewer bugs</li>
</ul>
<h3 id="anatomy-of-a-good-prompt">Anatomy of a Good Prompt</h3>
<pre><code>1. WHAT you want to build (the goal)
2. HOW it should work (technical details)
3. WHAT it should look like (design/output)
4. WHAT to include (specific features or libraries)
</code></pre>
<hr />
<h2 id="choosing-your-ai-coding-assistant">ü§ñ Choosing Your AI Coding Assistant</h2>
<p>For this workshop, you can use <strong>any</strong> of these AI coding assistants. They all work with the same prompts!</p>
<h3 id="option-1-qwen-coder-qoder">Option 1: Qwen Coder (Qoder)</h3>
<ul>
<li><strong>What it is:</strong> Open-source coding assistant from Alibaba</li>
<li><strong>How to access:</strong> Command line tool or API</li>
<li><strong>Best for:</strong> Students who want free, open-source options</li>
<li><strong>Setup:</strong> Follow installation instructions at https://github.com/QwenLM/Qwen-Coder</li>
</ul>
<h3 id="option-2-claude-code">Option 2: Claude Code</h3>
<ul>
<li><strong>What it is:</strong> Anthropic's command-line coding assistant</li>
<li><strong>How to access:</strong> Terminal/command line with Claude API key</li>
<li><strong>Best for:</strong> Complex reasoning and detailed explanations</li>
<li><strong>Setup:</strong> Requires Claude API key from console.anthropic.com</li>
</ul>
<h3 id="option-3-github-copilot">Option 3: GitHub Copilot</h3>
<ul>
<li><strong>What it is:</strong> AI pair programmer integrated into VS Code</li>
<li><strong>How to access:</strong> VS Code extension (paid subscription)</li>
<li><strong>Best for:</strong> Students already using VS Code</li>
<li><strong>Setup:</strong> Install GitHub Copilot extension in VS Code</li>
</ul>
<h3 id="option-4-gemini-code-assist-cli">Option 4: Gemini Code Assist (CLI)</h3>
<ul>
<li><strong>What it is:</strong> Google's coding assistant with CLI interface</li>
<li><strong>How to access:</strong> Command line or Google AI Studio</li>
<li><strong>Best for:</strong> Integration with Google Cloud services</li>
<li><strong>Setup:</strong> Google Cloud account + gcloud CLI</li>
</ul>
<h3 id="option-5-cursor-windsurf">Option 5: Cursor / Windsurf</h3>
<ul>
<li><strong>What it is:</strong> AI-powered code editors with built-in assistants</li>
<li><strong>How to access:</strong> Download the editor application</li>
<li><strong>Best for:</strong> Students who want an all-in-one IDE experience</li>
<li><strong>Setup:</strong> Download from cursor.sh or codeium.com</li>
</ul>
<h3 id="recommendation-for-todays-workshop">üí° Recommendation for Today's Workshop</h3>
<p><strong>Use whatever you have access to!</strong> All the prompts in this guide work with any AI coding assistant. The instructor will demonstrate with one tool, but the concepts are universal.</p>
<p><strong>If you don't have any:</strong> 
- Qwen Coder is free and open-source
- Gemini has a generous free tier
- Many tools offer free trials</p>
<hr />
<h2 id="main-prompt-creating-the-django-app">üöÄ Main Prompt: Creating the Django App</h2>
<h3 id="purpose">Purpose</h3>
<p>This prompt tells the AI coding agent to build a complete web application that:
- Accepts image uploads from users
- Sends images to an AI vision service
- Displays analysis results</p>
<h3 id="when-to-use">When to Use</h3>
<ul>
<li>At the start of your project</li>
<li>When you want to build the entire application from scratch</li>
</ul>
<h3 id="the-prompt-works-with-all-ai-assistants">The Prompt (Works with ALL AI assistants)</h3>
<pre><code>Create a Django web application called &quot;smartvision&quot; that allows users to upload images and get AI-powered analysis.

Requirements:
- Simple, modern upload interface with drag-and-drop support
- Send uploaded image to Google Gemini Vision API (gemini-1.5-flash model)
- Prompt to send to Gemini: &quot;Analyze this image in detail. Describe: 1) What objects you see, 2) The context/setting, 3) Three potential use cases for this image in a mobile app (e-commerce, social, utility, etc.)&quot;
- Display Gemini's response in a formatted card with nice typography
- Show the uploaded image alongside the analysis
- Use Django 4.2 and google-generativeai Python package
- Include proper error handling (API failures, unsupported file types)
- Add comments explaining the code flow
- Style with modern CSS (gradients, shadows, responsive design)
- Show a loading spinner while processing

Technical notes:
- Use Django's FileSystemStorage for temporary file handling
- API key should be read from environment variable GEMINI_API_KEY
- Support JPG, PNG, WEBP formats
- Limit file size to 5MB
</code></pre>
<h3 id="student-notes-why-each-part-matters">üìù Student Notes: Why Each Part Matters</h3>
<p><strong>"Create a Django web application called 'smartvision'"</strong>
‚Üí Tells AI which framework to use (Django) and what to name it</p>
<p><strong>"Simple, modern upload interface with drag-and-drop"</strong>
‚Üí Defines user experience - not just a boring button</p>
<p><strong>"Send uploaded image to Google Gemini Vision API"</strong>
‚Üí Specifies WHICH AI service (important - different APIs have different code)</p>
<p><strong>"Prompt to send to Gemini: 'Analyze this image...'"</strong>
‚Üí This is a "system prompt" - instructions for the AI vision model</p>
<p><strong>"Display Gemini's response in a formatted card"</strong>
‚Üí Makes results look professional, not just plain text</p>
<p><strong>"API key should be read from environment variable"</strong>
‚Üí Security best practice - never hardcode API keys in code!</p>
<p><strong>"Support JPG, PNG, WEBP formats"</strong>
‚Üí Defines constraints - helps catch errors early</p>
<h3 id="how-to-use-this-prompt-with-different-tools">üîÑ How to Use This Prompt with Different Tools</h3>
<h4 id="with-qwen-coder-qoder">With Qwen Coder / Qoder:</h4>
<pre><code class="language-bash"># In terminal
qwen-coder &quot;Create a Django web application called 'smartvision'...&quot;
</code></pre>
<h4 id="with-claude-code">With Claude Code:</h4>
<pre><code class="language-bash"># In terminal
claude-code &quot;Create a Django web application called 'smartvision'...&quot;
</code></pre>
<h4 id="with-github-copilot">With GitHub Copilot:</h4>
<pre><code>1. Open VS Code
2. Open Copilot Chat (Ctrl+Shift+I or Cmd+Shift+I)
3. Paste the prompt
4. Let Copilot generate the code
</code></pre>
<h4 id="with-gemini-cli">With Gemini CLI:</h4>
<pre><code class="language-bash"># In terminal
gemini code &quot;Create a Django web application called 'smartvision'...&quot;
</code></pre>
<h4 id="with-cursor">With Cursor:</h4>
<pre><code>1. Open Cursor editor
2. Press Ctrl+K (or Cmd+K on Mac)
3. Paste the prompt
4. Cursor will generate the code inline
</code></pre>
<hr />
<h2 id="system-prompt-image-analysis-instructions">üß† System Prompt: Image Analysis Instructions</h2>
<h3 id="what-is-a-system-prompt">What is a System Prompt?</h3>
<p>A system prompt is the instruction YOU send to the AI vision service (like Gemini) telling it HOW to analyze the image. It's different from the prompt you give your AI coding assistant.</p>
<h3 id="flow-diagram">Flow Diagram</h3>
<pre><code>You ‚Üí AI Coding Assistant (Qwen/Claude/Copilot/etc.)
         ‚Üì
    Builds Django App ‚Üí Gemini API (analyzes image)
         ‚Üì
    System Prompt: &quot;Analyze this image and describe...&quot;
</code></pre>
<h3 id="basic-system-prompt-general-analysis">Basic System Prompt (General Analysis)</h3>
<pre><code>Analyze this image in detail. Describe:
1) What objects you see
2) The context/setting
3) Three potential use cases for this image in a mobile app
</code></pre>
<p><strong>Why this works:</strong>
- Numbered list = structured response
- "In detail" = AI doesn't give one-word answers
- "Potential use cases" = makes it practical for students' projects</p>
<h3 id="alternative-system-prompts-for-different-use-cases">Alternative System Prompts (For Different Use Cases)</h3>
<h4 id="product-e-commerce">Product E-commerce</h4>
<pre><code>You are a product catalog AI. Analyze this product image and provide:
- Product category
- Key features visible
- Suggested product title
- Estimated condition (new/used/damaged)
- Suggested price range in USD
- 5 SEO keywords for listing
</code></pre>
<h4 id="foodrecipe-app">Food/Recipe App</h4>
<pre><code>Analyze this food image and provide:
- Main dish/ingredient identification
- Cuisine type
- Suggested recipe name
- Key ingredients visible
- Dietary tags (vegetarian, gluten-free, etc.)
</code></pre>
<h4 id="fashionclothing-app">Fashion/Clothing App</h4>
<pre><code>Analyze this clothing/outfit image:
- Clothing type and style
- Colors present
- Occasion/setting (casual, formal, sportswear)
- Season suitability
- Suggested outfit pairings
</code></pre>
<h4 id="documenttext-extraction">Document/Text Extraction</h4>
<pre><code>Extract all text from this image. If it's a form or document:
- Identify document type
- Extract key fields (names, dates, amounts)
- Highlight any important information
- Note if anything is unclear or unreadable
</code></pre>
<h3 id="teaching-moment-how-to-write-good-system-prompts">üéì Teaching Moment: How to Write Good System Prompts</h3>
<p><strong>Bad System Prompt:</strong></p>
<pre><code>Tell me about this image.
</code></pre>
<p>‚Üí Too vague! AI might give you anything.</p>
<p><strong>Good System Prompt:</strong></p>
<pre><code>You are an expert art curator. Analyze this artwork and describe:
1. Art style and period
2. Dominant colors and mood
3. Subject matter
4. Estimated value range if known
</code></pre>
<p>‚Üí Specific role, clear structure, defined output!</p>
<p><strong>Key Principles:</strong>
1. <strong>Be specific</strong> - Tell AI what you want, not what you don't want
2. <strong>Give structure</strong> - Use numbered lists or bullet points
3. <strong>Define output format</strong> - JSON? Plain text? Bullet points?
4. <strong>Set context</strong> - "You are a [expert]..." helps AI respond appropriately</p>
<hr />
<h2 id="iteration-prompts-adding-features">üîÑ Iteration Prompts: Adding Features</h2>
<h3 id="purpose_1">Purpose</h3>
<p>After you have a working basic app, use these prompts to add more features one at a time.</p>
<h3 id="prompt-1-save-analysis-history">Prompt 1: Save Analysis History</h3>
<pre><code>Modify the application to:
- Save the last 10 uploaded images and their AI analysis results to SQLite database
- Display them in a gallery below the upload form
- Each gallery item shows: thumbnail, analysis snippet, timestamp
- Add a &quot;Delete&quot; button for each saved item
- Use Django models to store: image file path, analysis text, upload date
</code></pre>
<p><strong>What students learn:</strong> Database integration, data persistence</p>
<h3 id="prompt-2-compare-two-images">Prompt 2: Compare Two Images</h3>
<pre><code>Add a &quot;Compare Mode&quot; feature:
- User can select 2 previously uploaded images from the gallery
- Add a &quot;Compare&quot; button that sends both images to Gemini
- System prompt for comparison: &quot;Compare these two images. Describe similarities, differences, and which would be better for [e-commerce product listing]&quot;
- Display comparison side-by-side with images
</code></pre>
<p><strong>What students learn:</strong> Multi-image processing, UI state management</p>
<h3 id="prompt-3-add-user-authentication">Prompt 3: Add User Authentication</h3>
<pre><code>Add user authentication to the app:
- Use Django's built-in authentication system
- Users must register/login to upload images
- Each user sees only THEIR uploaded images
- Add a simple profile page showing upload count
- Style the login/register pages to match the main app design
</code></pre>
<p><strong>What students learn:</strong> User management, data isolation</p>
<h3 id="prompt-4-export-results-to-pdf">Prompt 4: Export Results to PDF</h3>
<pre><code>Add a &quot;Download Report&quot; feature:
- Create a button on each analysis result
- Generate a PDF report containing: uploaded image, full analysis text, timestamp, your app branding
- Use ReportLab library for PDF generation
- Style the PDF professionally with headers and formatting
</code></pre>
<p><strong>What students learn:</strong> File generation, third-party libraries</p>
<h3 id="prompt-5-add-real-time-processing-indicator">Prompt 5: Add Real-time Processing Indicator</h3>
<pre><code>Improve the user experience:
- Replace simple loading spinner with a progress indicator
- Show status messages: &quot;Uploading image...&quot;, &quot;Sending to AI...&quot;, &quot;Processing results...&quot;
- Use JavaScript fetch API with progress events
- Add animations for each stage
</code></pre>
<p><strong>What students learn:</strong> Frontend interactivity, async operations</p>
<hr />
<h2 id="debugging-prompts">üêõ Debugging Prompts</h2>
<h3 id="when-code-doesnt-run">When Code Doesn't Run</h3>
<pre><code>I'm getting this error when running the Django app:
[paste the error message here]

The error occurs when [describe what you were doing].
Can you explain what's wrong and how to fix it?
</code></pre>
<h3 id="when-api-calls-fail">When API Calls Fail</h3>
<pre><code>The app runs but the API call to Gemini fails with this error:
[paste error]

Here's my current code:
[paste the relevant view function]

My GEMINI_API_KEY is set in the environment. What could be wrong?
</code></pre>
<h3 id="when-styling-looks-broken">When Styling Looks Broken</h3>
<pre><code>The upload form displays but the CSS styling isn't working correctly. The page looks like [describe the problem].

Can you check the CSS and fix the layout to ensure:
- The upload area is centered
- The form is responsive on mobile
- Colors match the gradient theme
</code></pre>
<h3 id="when-features-dont-work-as-expected">When Features Don't Work As Expected</h3>
<pre><code>I added the [feature name] but it's not working as expected. Instead of [expected behavior], it's [actual behavior].

Can you review the code and suggest fixes?
</code></pre>
<hr />
<h2 id="api-specific-notes">üîå API-Specific Notes</h2>
<h3 id="google-gemini-api">Google Gemini API</h3>
<p><strong>API Key Setup:</strong></p>
<pre><code class="language-bash"># In terminal/command prompt
export GEMINI_API_KEY=&quot;your_key_here&quot;

# Or in .env file
GEMINI_API_KEY=your_key_here
</code></pre>
<p><strong>Python Code Pattern:</strong></p>
<pre><code class="language-python">import google.generativeai as genai

genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
model = genai.GenerativeModel('gemini-1.5-flash')

# For images
response = model.generate_content([
    &quot;Your system prompt here&quot;,
    {&quot;mime_type&quot;: &quot;image/jpeg&quot;, &quot;data&quot;: base64_image_data}
])
</code></pre>
<p><strong>Free Tier:</strong> 1,500 requests per day
<strong>Best for:</strong> Students, demos, prototypes</p>
<hr />
<h3 id="openai-vision-api-gpt-4-vision">OpenAI Vision API (GPT-4 Vision)</h3>
<p><strong>API Key Setup:</strong></p>
<pre><code class="language-bash">export OPENAI_API_KEY=&quot;your_key_here&quot;
</code></pre>
<p><strong>Python Code Pattern:</strong></p>
<pre><code class="language-python">from openai import OpenAI

client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

response = client.chat.completions.create(
    model=&quot;gpt-4-vision-preview&quot;,
    messages=[{
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;Your system prompt here&quot;},
            {&quot;type&quot;: &quot;image_url&quot;, &quot;image_url&quot;: {&quot;url&quot;: f&quot;data:image/jpeg;base64,{base64_image}&quot;}}
        ]
    }]
)
</code></pre>
<p><strong>Pricing:</strong> Pay per use (~$0.01 per image)
<strong>Best for:</strong> Production apps, high accuracy needs</p>
<hr />
<h3 id="deepseek-vision-api-if-available">DeepSeek Vision API (If Available)</h3>
<p><strong>Status:</strong> As of early 2025, vision capabilities through DeepSeek-VL2 model
<strong>Note:</strong> API access may be limited or through third-party platforms</p>
<p><strong>If you have access:</strong></p>
<pre><code class="language-python"># DeepSeek uses OpenAI-compatible format
from openai import OpenAI

client = OpenAI(
    api_key=os.getenv('DEEPSEEK_API_KEY'),
    base_url=&quot;https://api.deepseek.com&quot;
)

# Similar usage to OpenAI
</code></pre>
<p><strong>Why we're NOT using it today:</strong>
- Unclear API access for vision features
- Recent stability issues reported
- Limited documentation for vision endpoints</p>
<hr />
<h2 id="key-concepts-for-students">üéì Key Concepts for Students</h2>
<h3 id="1-prompt-engineering-is-a-skill">1. Prompt Engineering is a Skill</h3>
<p>Writing good prompts is like writing good requirements. The better your prompt, the better your code.</p>
<h3 id="2-iteration-is-normal">2. Iteration is Normal</h3>
<p>You won't get perfect code on the first try. Use iteration prompts to refine features.</p>
<h3 id="3-system-prompts-vs-code-prompts">3. System Prompts vs Code Prompts</h3>
<ul>
<li><strong>Code prompt</strong> ‚Üí Instructions for your AI coding assistant (Qwen/Claude/Copilot) to write code</li>
<li><strong>System prompt</strong> ‚Üí Instructions sent TO the AI vision API in your code</li>
</ul>
<h3 id="4-api-keys-are-secrets">4. API Keys are Secrets</h3>
<p>Never commit API keys to GitHub! Always use environment variables.</p>
<h3 id="5-different-apis-same-pattern">5. Different APIs, Same Pattern</h3>
<p>All vision APIs follow similar patterns:
1. Send image (as URL or base64)
2. Send text prompt
3. Receive structured response</p>
<p>The code syntax differs, but the CONCEPT is identical.</p>
<h3 id="6-different-ai-assistants-same-prompts">6. Different AI Assistants, Same Prompts</h3>
<p>Whether you use Qwen Coder, Claude Code, GitHub Copilot, or another tool, the prompts are the same. They all understand the same instructions!</p>
<hr />
<h2 id="pro-tips">üí° Pro Tips</h2>
<h3 id="for-your-week-11-project">For Your Week 11 Project</h3>
<ol>
<li><strong>Start with the basic prompt</strong> - Get something working first</li>
<li><strong>Test with multiple images</strong> - Different lighting, angles, quality</li>
<li><strong>Handle errors gracefully</strong> - What if API is down? Show user a nice message</li>
<li><strong>Consider rate limits</strong> - Don't spam the API, add delays between requests</li>
<li><strong>Document your prompts</strong> - Save the system prompts you use in a file</li>
</ol>
<h3 id="questions-to-ask-yourself">Questions to Ask Yourself</h3>
<p>Before writing a prompt:
- What EXACTLY do I want the AI to build/do?
- What libraries or tools should it use?
- What should the output look like?
- What errors might occur and how should they be handled?</p>
<h3 id="common-mistakes-to-avoid">Common Mistakes to Avoid</h3>
<p>‚ùå "Make me an app with AI"
‚Üí Too vague!</p>
<p>‚úÖ "Create a Flask app that uses OpenAI Vision API to analyze product photos and suggest titles"</p>
<p>‚ùå "Fix my code"
‚Üí Doesn't provide context!</p>
<p>‚úÖ "I'm getting a 401 error when calling the API. Here's my code [paste]. My API key is set. What's wrong?"</p>
<hr />
<h2 id="tool-specific-tips">üõ†Ô∏è Tool-Specific Tips</h2>
<h3 id="for-qwen-coder-users">For Qwen Coder Users</h3>
<ul>
<li>Works great with Python and web frameworks</li>
<li>Can run locally without internet (some models)</li>
<li>Good for understanding code step-by-step</li>
</ul>
<h3 id="for-claude-code-users">For Claude Code Users</h3>
<ul>
<li>Excellent at explaining complex concepts</li>
<li>Great for debugging and error analysis</li>
<li>Strong with architectural decisions</li>
</ul>
<h3 id="for-github-copilot-users">For GitHub Copilot Users</h3>
<ul>
<li>Best when writing code line-by-line</li>
<li>Great autocomplete suggestions</li>
<li>Works seamlessly in VS Code</li>
</ul>
<h3 id="for-gemini-cli-users">For Gemini CLI Users</h3>
<ul>
<li>Easy integration with Google Cloud</li>
<li>Good for multimodal tasks</li>
<li>Generous free tier</li>
</ul>
<hr />
<hr />
<h2 id="integrating-with-your-no-code-tools-adalo-softr-bolt">üîå Integrating with Your No-Code Tools (Adalo, Softr, Bolt)</h2>
<h3 id="the-challenge">The Challenge</h3>
<p>Your no-code tools (Adalo free, Softr, Bolt.new) can't directly call AI vision APIs because:
1. <strong>Security</strong> - Can't expose API keys in the frontend
2. <strong>CORS restrictions</strong> - Browser security blocks direct API calls
3. <strong>API complexity</strong> - Vision APIs need server-side processing</p>
<h3 id="the-solution-add-a-middle-server">The Solution: Add a Middle Server</h3>
<pre><code>[Your Adalo/Softr App] 
        ‚Üì HTTP POST
[Your Django/Flask Server on Railway/Render] 
        ‚Üì Secure API call
[Gemini/OpenAI Vision API]
        ‚Üì Results
[Your Server] 
        ‚Üì JSON response
[Your App displays results]
</code></pre>
<h3 id="option-1-use-railway-recommended-free-tier-available">Option 1: Use Railway (Recommended - Free Tier Available)</h3>
<p><strong>Why Railway?</strong>
- ‚úÖ Free tier: $5 credit/month (enough for demos)
- ‚úÖ Easy deployment from GitHub
- ‚úÖ No credit card required for trial
- ‚úÖ Better than Vercel for Django/Flask
- ‚úÖ Automatic HTTPS</p>
<p><strong>Deployment Steps:</strong>
1. Push your Django code to GitHub
2. Go to railway.app
3. Click "Start a New Project" ‚Üí "Deploy from GitHub"
4. Select your repository
5. Railway auto-detects Django and deploys
6. Add environment variable: <code>GEMINI_API_KEY</code>
7. Get your public URL: <code>https://yourapp.railway.app</code></p>
<p><strong>In Adalo/Softr:</strong></p>
<pre><code>API Endpoint: https://yourapp.railway.app/analyze
Method: POST
Body: {&quot;image_url&quot;: &quot;https://...&quot;}
Headers: {&quot;Content-Type&quot;: &quot;application/json&quot;}
</code></pre>
<h3 id="option-2-use-render-also-free-tier">Option 2: Use Render (Also Free Tier)</h3>
<p><strong>Why Render?</strong>
- ‚úÖ Free tier (no credit card needed)
- ‚úÖ Simple setup
- ‚úÖ Good documentation
- ‚úÖ Auto-deploy from GitHub</p>
<p><strong>Deployment Steps:</strong>
1. Push code to GitHub
2. Go to render.com
3. New ‚Üí Web Service
4. Connect GitHub repository
5. Render auto-builds
6. Add environment variable: <code>GEMINI_API_KEY</code>
7. Get URL: <code>https://yourapp.onrender.com</code></p>
<p><strong>Note:</strong> Free tier sleeps after 15 min inactivity (first request takes ~30 sec to wake up)</p>
<h3 id="option-3-use-pythonanywhere-beginner-friendly">Option 3: Use PythonAnywhere (Beginner-Friendly)</h3>
<p><strong>Why PythonAnywhere?</strong>
- ‚úÖ Forever free tier
- ‚úÖ No credit card required
- ‚úÖ Web-based file editor
- ‚úÖ Good for learning</p>
<p><strong>Deployment Steps:</strong>
1. Sign up at pythonanywhere.com (free)
2. Open a Bash console
3. Clone your repo: <code>git clone https://github.com/yourusername/yourrepo</code>
4. Set up virtual environment
5. Configure web app in "Web" tab
6. Set environment variables in "Web" tab
7. URL: <code>https://yourusername.pythonanywhere.com</code></p>
<p><strong>Limitations:</strong> No automatic GitHub deployments on free tier</p>
<h3 id="how-to-connect-from-adalo">How to Connect from Adalo</h3>
<p><strong>Step 1: Create API Endpoint in Your App</strong>
Your Django view should accept POST requests:</p>
<pre><code class="language-python"># views.py
def analyze_image_api(request):
    if request.method == 'POST':
        image_url = request.POST.get('image_url')
        # Process with Gemini API
        result = analyze_image(image_url)
        return JsonResponse({'result': result})
</code></pre>
<p><strong>Step 2: In Adalo</strong>
1. Add "Custom Action" to your button
2. Method: POST
3. URL: <code>https://yourapp.railway.app/api/analyze</code>
4. Body: </p>
<pre><code class="language-json">{
  &quot;image_url&quot;: &quot;{{ImageComponent.URL}}&quot;
}
</code></pre>
<ol>
<li>Save response as a variable</li>
<li>Display in Text component: <code>{{APIResponse.result}}</code></li>
</ol>
<p><strong>Limitations:</strong> Adalo free tier may have API call restrictions</p>
<h3 id="how-to-connect-from-softr">How to Connect from Softr</h3>
<p><strong>Step 1: Use Airtable as Bridge</strong>
Softr works best with Airtable. Strategy:
1. User uploads image to Softr form ‚Üí saves to Airtable
2. Airtable Automation triggers when new record created
3. Automation calls your Railway/Render API via Webhook
4. API analyzes image and returns result
5. Automation updates Airtable record with result
6. Softr displays the updated record</p>
<p><strong>Step 2: Airtable Automation Setup</strong>
1. In Airtable: Create automation
2. Trigger: "When record created"
3. Action: "Send webhook"
4. Webhook URL: <code>https://yourapp.railway.app/api/analyze</code>
5. Method: POST
6. Body: <code>{"image_url": "{{Image URL from record}}"}</code>
7. Parse response and update same record</p>
<h3 id="how-to-connect-from-boltnew">How to Connect from Bolt.new</h3>
<p><strong>Option A: Bolt.new Already Has Backend Capabilities</strong>
Bolt.new generates full-stack code, so you can add API calls directly:</p>
<ol>
<li>Ask Bolt: "Add a backend API route that accepts image uploads and calls Gemini API"</li>
<li>Bolt generates both frontend and backend</li>
<li>Deploy the entire app to Railway/Render</li>
<li>No separate server needed!</li>
</ol>
<p><strong>Option B: Call External API</strong>
If you built the Django app separately:</p>
<pre><code class="language-javascript">// In Bolt.new generated code
async function analyzeImage(imageFile) {
  const formData = new FormData();
  formData.append('image', imageFile);

  const response = await fetch('https://yourapp.railway.app/api/analyze', {
    method: 'POST',
    body: formData
  });

  const result = await response.json();
  return result;
}
</code></pre>
<h3 id="security-considerations">Security Considerations</h3>
<p><strong>‚ùå NEVER Do This:</strong></p>
<pre><code class="language-javascript">// DON'T put API keys in frontend code!
const apiKey = &quot;AIzaSy...&quot;; // ‚Üê Visible to everyone!
</code></pre>
<p><strong>‚úÖ ALWAYS Do This:</strong></p>
<pre><code class="language-python"># Django backend - API key is safe on server
api_key = os.getenv('GEMINI_API_KEY')  # ‚Üê Only visible on server
</code></pre>
<h3 id="free-tier-comparison">Free Tier Comparison</h3>
<table>
<thead>
<tr>
<th>Service</th>
<th>Free Tier</th>
<th>Requires Card?</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Railway</strong></td>
<td>$5 credit/month</td>
<td>No (trial)</td>
<td>Django, Flask, Quick deploys</td>
</tr>
<tr>
<td><strong>Render</strong></td>
<td>750 hours/month</td>
<td>No</td>
<td>Simple apps, auto-deploy</td>
</tr>
<tr>
<td><strong>PythonAnywhere</strong></td>
<td>Forever free</td>
<td>No</td>
<td>Learning, permanent hosting</td>
</tr>
<tr>
<td><strong>Vercel</strong></td>
<td>Good for Next.js</td>
<td>No</td>
<td>NOT recommended for Django</td>
</tr>
<tr>
<td><strong>Netlify</strong></td>
<td>Static sites only</td>
<td>No</td>
<td>NOT for backend APIs</td>
</tr>
</tbody>
</table>
<h3 id="high-level-integration-summary">High-Level Integration Summary</h3>
<p><strong>What You Need:</strong>
1. ‚úÖ Your Django app with API endpoint (already built in workshop)
2. ‚úÖ Free hosting account (Railway or Render)
3. ‚úÖ GitHub repository
4. ‚úÖ 10 minutes to deploy</p>
<p><strong>What Your No-Code Tool Needs:</strong>
- <strong>Adalo</strong>: Custom action with POST request
- <strong>Softr</strong>: Airtable automation webhook
- <strong>Bolt.new</strong>: Fetch API call in generated code</p>
<p><strong>Result:</strong></p>
<pre><code>User uploads image in Adalo/Softr/Bolt
    ‚Üì
Your server analyzes it with Gemini
    ‚Üì
Results display in your app
</code></pre>
<h3 id="troubleshooting-common-issues">Troubleshooting Common Issues</h3>
<p><strong>Issue: "CORS Error"</strong>
‚Üí Add CORS headers to your Django app:</p>
<pre><code class="language-python"># settings.py
CORS_ALLOW_ALL_ORIGINS = True  # For development
</code></pre>
<p><strong>Issue: "API key not found"</strong>
‚Üí Check environment variables are set in Railway/Render dashboard</p>
<p><strong>Issue: "Request timeout"</strong>
‚Üí Render free tier sleeps. First request takes 30 sec. Warn users to wait.</p>
<p><strong>Issue: "Too expensive"</strong>
‚Üí Use Railway's free $5/month. Set up usage alerts. Should be enough for 100-500 requests.</p>
<h3 id="workshop-recommendation">Workshop Recommendation</h3>
<p><strong>For Today's Demo:</strong>
Focus on building the Django app locally. Explain that deploying to Railway/Render is optional for Week 11 projects.</p>
<p><strong>For Week 11 Projects:</strong>
Students who want to integrate with Adalo/Softr should:
1. Deploy their Django backend to Railway (free tier)
2. Follow the integration guide for their specific tool
3. Test with 5-10 images first (to avoid running out of free credits)</p>
<hr />
<h2 id="additional-resources">üìö Additional Resources</h2>
<h3 id="official-documentation">Official Documentation</h3>
<ul>
<li>Google Gemini API: https://ai.google.dev/</li>
<li>OpenAI Vision API: https://platform.openai.com/docs/guides/vision</li>
<li>Django Documentation: https://docs.djangoproject.com/</li>
<li>Qwen Coder: https://github.com/QwenLM/Qwen-Coder</li>
</ul>
<h3 id="learning-prompt-engineering">Learning Prompt Engineering</h3>
<ul>
<li>Anthropic's Prompt Engineering Guide: https://docs.anthropic.com/prompt-engineering</li>
<li>OpenAI Prompt Engineering Guide: https://platform.openai.com/docs/guides/prompt-engineering</li>
</ul>
<h3 id="ai-coding-assistants">AI Coding Assistants</h3>
<ul>
<li>Qwen Coder GitHub: https://github.com/QwenLM/Qwen-Coder</li>
<li>Claude Code Docs: https://docs.anthropic.com/</li>
<li>GitHub Copilot: https://github.com/features/copilot</li>
<li>Cursor: https://cursor.sh</li>
<li>Windsurf: https://codeium.com/windsurf</li>
</ul>
<hr />
<h2 id="workshop-challenge">üéØ Workshop Challenge</h2>
<p><strong>Try this after the demo:</strong></p>
<p>Use the prompts in this guide to build YOUR OWN version of the image analysis app, but customize it for YOUR Week 11 project idea.</p>
<ol>
<li>Choose your AI coding assistant (Qwen, Claude, Copilot, etc.)</li>
<li>Start with the main prompt</li>
<li>Modify the system prompt to fit your use case</li>
<li>Add 1-2 features using the iteration prompts</li>
<li>Share what you built with your team!</li>
</ol>
<p>Remember: The best way to learn is by doing. Don't just watch - code along!</p>
<hr />
<p><strong>Questions?</strong> Ask during the workshop or experiment on your own. The worst that can happen is you learn what NOT to do! üòä</p>
<h3 id="basic-system-prompt-general-analysis_1">Basic System Prompt (General Analysis)</h3>
<pre><code>Analyze this image in detail. Describe:
1) What objects you see
2) The context/setting
3) Three potential use cases for this image in a mobile app
</code></pre>
<p><strong>Why this works:</strong>
- Numbered list = structured response
- "In detail" = AI doesn't give one-word answers
- "Potential use cases" = makes it practical for students' projects</p>
<h3 id="alternative-system-prompts-for-different-use-cases_1">Alternative System Prompts (For Different Use Cases)</h3>
<h4 id="product-e-commerce_1">Product E-commerce</h4>
<pre><code>You are a product catalog AI. Analyze this product image and provide:
- Product category
- Key features visible
- Suggested product title
- Estimated condition (new/used/damaged)
- Suggested price range in USD
- 5 SEO keywords for listing
</code></pre>
<h4 id="foodrecipe-app_1">Food/Recipe App</h4>
<pre><code>Analyze this food image and provide:
- Main dish/ingredient identification
- Cuisine type
- Suggested recipe name
- Key ingredients visible
- Dietary tags (vegetarian, gluten-free, etc.)
</code></pre>
<h4 id="fashionclothing-app_1">Fashion/Clothing App</h4>
<pre><code>Analyze this clothing/outfit image:
- Clothing type and style
- Colors present
- Occasion/setting (casual, formal, sportswear)
- Season suitability
- Suggested outfit pairings
</code></pre>
<h4 id="documenttext-extraction_1">Document/Text Extraction</h4>
<pre><code>Extract all text from this image. If it's a form or document:
- Identify document type
- Extract key fields (names, dates, amounts)
- Highlight any important information
- Note if anything is unclear or unreadable
</code></pre>
<h3 id="teaching-moment-how-to-write-good-system-prompts_1">üéì Teaching Moment: How to Write Good System Prompts</h3>
<p><strong>Bad System Prompt:</strong></p>
<pre><code>Tell me about this image.
</code></pre>
<p>‚Üí Too vague! AI might give you anything.</p>
<p><strong>Good System Prompt:</strong></p>
<pre><code>You are an expert art curator. Analyze this artwork and describe:
1. Art style and period
2. Dominant colors and mood
3. Subject matter
4. Estimated value range if known
</code></pre>
<p>‚Üí Specific role, clear structure, defined output!</p>
<p><strong>Key Principles:</strong>
1. <strong>Be specific</strong> - Tell AI what you want, not what you don't want
2. <strong>Give structure</strong> - Use numbered lists or bullet points
3. <strong>Define output format</strong> - JSON? Plain text? Bullet points?
4. <strong>Set context</strong> - "You are a [expert]..." helps AI respond appropriately</p>
<hr />
<h2 id="iteration-prompts-adding-features_1">üîÑ Iteration Prompts: Adding Features</h2>
<h3 id="purpose_2">Purpose</h3>
<p>After you have a working basic app, use these prompts to add more features one at a time.</p>
<h3 id="prompt-1-save-analysis-history_1">Prompt 1: Save Analysis History</h3>
<pre><code>Modify the application to:
- Save the last 10 uploaded images and their AI analysis results to SQLite database
- Display them in a gallery below the upload form
- Each gallery item shows: thumbnail, analysis snippet, timestamp
- Add a &quot;Delete&quot; button for each saved item
- Use Django models to store: image file path, analysis text, upload date
</code></pre>
<p><strong>What students learn:</strong> Database integration, data persistence</p>
<h3 id="prompt-2-compare-two-images_1">Prompt 2: Compare Two Images</h3>
<pre><code>Add a &quot;Compare Mode&quot; feature:
- User can select 2 previously uploaded images from the gallery
- Add a &quot;Compare&quot; button that sends both images to Gemini
- System prompt for comparison: &quot;Compare these two images. Describe similarities, differences, and which would be better for [e-commerce product listing]&quot;
- Display comparison side-by-side with images
</code></pre>
<p><strong>What students learn:</strong> Multi-image processing, UI state management</p>
<h3 id="prompt-3-add-user-authentication_1">Prompt 3: Add User Authentication</h3>
<pre><code>Add user authentication to the app:
- Use Django's built-in authentication system
- Users must register/login to upload images
- Each user sees only THEIR uploaded images
- Add a simple profile page showing upload count
- Style the login/register pages to match the main app design
</code></pre>
<p><strong>What students learn:</strong> User management, data isolation</p>
<h3 id="prompt-4-export-results-to-pdf_1">Prompt 4: Export Results to PDF</h3>
<pre><code>Add a &quot;Download Report&quot; feature:
- Create a button on each analysis result
- Generate a PDF report containing: uploaded image, full analysis text, timestamp, your app branding
- Use ReportLab library for PDF generation
- Style the PDF professionally with headers and formatting
</code></pre>
<p><strong>What students learn:</strong> File generation, third-party libraries</p>
<h3 id="prompt-5-add-real-time-processing-indicator_1">Prompt 5: Add Real-time Processing Indicator</h3>
<pre><code>Improve the user experience:
- Replace simple loading spinner with a progress indicator
- Show status messages: &quot;Uploading image...&quot;, &quot;Sending to AI...&quot;, &quot;Processing results...&quot;
- Use JavaScript fetch API with progress events
- Add animations for each stage
</code></pre>
<p><strong>What students learn:</strong> Frontend interactivity, async operations</p>
<hr />
<h2 id="debugging-prompts_1">üêõ Debugging Prompts</h2>
<h3 id="when-code-doesnt-run_1">When Code Doesn't Run</h3>
<pre><code>I'm getting this error when running the Django app:
[paste the error message here]

The error occurs when [describe what you were doing].
Can you explain what's wrong and how to fix it?
</code></pre>
<h3 id="when-api-calls-fail_1">When API Calls Fail</h3>
<pre><code>The app runs but the API call to Gemini fails with this error:
[paste error]

Here's my current code:
[paste the relevant view function]

My GEMINI_API_KEY is set in the environment. What could be wrong?
</code></pre>
<h3 id="when-styling-looks-broken_1">When Styling Looks Broken</h3>
<pre><code>The upload form displays but the CSS styling isn't working correctly. The page looks like [describe the problem].

Can you check the CSS and fix the layout to ensure:
- The upload area is centered
- The form is responsive on mobile
- Colors match the gradient theme
</code></pre>
<h3 id="when-features-dont-work-as-expected_1">When Features Don't Work As Expected</h3>
<pre><code>I added the [feature name] but it's not working as expected. Instead of [expected behavior], it's [actual behavior].

Can you review the code and suggest fixes?
</code></pre>
<hr />
<h2 id="api-specific-notes_1">üîå API-Specific Notes</h2>
<h3 id="google-gemini-api_1">Google Gemini API</h3>
<p><strong>API Key Setup:</strong></p>
<pre><code class="language-bash"># In terminal/command prompt
export GEMINI_API_KEY=&quot;your_key_here&quot;

# Or in .env file
GEMINI_API_KEY=your_key_here
</code></pre>
<p><strong>Python Code Pattern:</strong></p>
<pre><code class="language-python">import google.generativeai as genai

genai.configure(api_key=os.getenv('GEMINI_API_KEY'))
model = genai.GenerativeModel('gemini-1.5-flash')

# For images
response = model.generate_content([
    &quot;Your system prompt here&quot;,
    {&quot;mime_type&quot;: &quot;image/jpeg&quot;, &quot;data&quot;: base64_image_data}
])
</code></pre>
<p><strong>Free Tier:</strong> 1,500 requests per day
<strong>Best for:</strong> Students, demos, prototypes</p>
<hr />
<h3 id="openai-vision-api-gpt-4-vision_1">OpenAI Vision API (GPT-4 Vision)</h3>
<p><strong>API Key Setup:</strong></p>
<pre><code class="language-bash">export OPENAI_API_KEY=&quot;your_key_here&quot;
</code></pre>
<p><strong>Python Code Pattern:</strong></p>
<pre><code class="language-python">from openai import OpenAI

client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

response = client.chat.completions.create(
    model=&quot;gpt-4-vision-preview&quot;,
    messages=[{
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: [
            {&quot;type&quot;: &quot;text&quot;, &quot;text&quot;: &quot;Your system prompt here&quot;},
            {&quot;type&quot;: &quot;image_url&quot;, &quot;image_url&quot;: {&quot;url&quot;: f&quot;data:image/jpeg;base64,{base64_image}&quot;}}
        ]
    }]
)
</code></pre>
<p><strong>Pricing:</strong> Pay per use (~$0.01 per image)
<strong>Best for:</strong> Production apps, high accuracy needs</p>
<hr />
<h3 id="deepseek-vision-api-if-available_1">DeepSeek Vision API (If Available)</h3>
<p><strong>Status:</strong> As of early 2025, vision capabilities through DeepSeek-VL2 model
<strong>Note:</strong> API access may be limited or through third-party platforms</p>
<p><strong>If you have access:</strong></p>
<pre><code class="language-python"># DeepSeek uses OpenAI-compatible format
from openai import OpenAI

client = OpenAI(
    api_key=os.getenv('DEEPSEEK_API_KEY'),
    base_url=&quot;https://api.deepseek.com&quot;
)

# Similar usage to OpenAI
</code></pre>
<p><strong>Why we're NOT using it today:</strong>
- Unclear API access for vision features
- Recent stability issues reported
- Limited documentation for vision endpoints</p>
<hr />
<h2 id="key-concepts-for-students_1">üéì Key Concepts for Students</h2>
<h3 id="1-prompt-engineering-is-a-skill_1">1. Prompt Engineering is a Skill</h3>
<p>Writing good prompts is like writing good requirements. The better your prompt, the better your code.</p>
<h3 id="2-iteration-is-normal_1">2. Iteration is Normal</h3>
<p>You won't get perfect code on the first try. Use iteration prompts to refine features.</p>
<h3 id="3-system-prompts-vs-code-prompts_1">3. System Prompts vs Code Prompts</h3>
<ul>
<li><strong>Code prompt</strong> ‚Üí Instructions for Claude/ChatGPT to write code</li>
<li><strong>System prompt</strong> ‚Üí Instructions sent TO the AI vision API in your code</li>
</ul>
<h3 id="4-api-keys-are-secrets_1">4. API Keys are Secrets</h3>
<p>Never commit API keys to GitHub! Always use environment variables.</p>
<h3 id="5-different-apis-same-pattern_1">5. Different APIs, Same Pattern</h3>
<p>All vision APIs follow similar patterns:
1. Send image (as URL or base64)
2. Send text prompt
3. Receive structured response</p>
<p>The code syntax differs, but the CONCEPT is identical.</p>
<hr />
<h2 id="pro-tips_1">üí° Pro Tips</h2>
<h3 id="for-your-week-11-project_1">For Your Week 11 Project</h3>
<ol>
<li><strong>Start with the basic prompt</strong> - Get something working first</li>
<li><strong>Test with multiple images</strong> - Different lighting, angles, quality</li>
<li><strong>Handle errors gracefully</strong> - What if API is down? Show user a nice message</li>
<li><strong>Consider rate limits</strong> - Don't spam the API, add delays between requests</li>
<li><strong>Document your prompts</strong> - Save the system prompts you use in a file</li>
</ol>
<h3 id="questions-to-ask-yourself_1">Questions to Ask Yourself</h3>
<p>Before writing a prompt:
- What EXACTLY do I want the AI to build/do?
- What libraries or tools should it use?
- What should the output look like?
- What errors might occur and how should they be handled?</p>
<h3 id="common-mistakes-to-avoid_1">Common Mistakes to Avoid</h3>
<p>‚ùå "Make me an app with AI"
‚Üí Too vague!</p>
<p>‚úÖ "Create a Flask app that uses OpenAI Vision API to analyze product photos and suggest titles"</p>
<p>‚ùå "Fix my code"
‚Üí Doesn't provide context!</p>
<p>‚úÖ "I'm getting a 401 error when calling the API. Here's my code [paste]. My API key is set. What's wrong?"</p>
<hr />
<hr />
<h2 id="integrating-with-your-no-code-tools-adalo-softr-bolt_1">üîå Integrating with Your No-Code Tools (Adalo, Softr, Bolt)</h2>
<h3 id="the-challenge_1">The Challenge</h3>
<p>Your no-code tools (Adalo free, Softr, Bolt.new) can't directly call AI vision APIs because:
1. <strong>Security</strong> - Can't expose API keys in the frontend
2. <strong>CORS restrictions</strong> - Browser security blocks direct API calls
3. <strong>API complexity</strong> - Vision APIs need server-side processing</p>
<h3 id="the-solution-add-a-middle-server_1">The Solution: Add a Middle Server</h3>
<pre><code>[Your Adalo/Softr App] 
        ‚Üì HTTP POST
[Your Django/Flask Server on Railway/Render] 
        ‚Üì Secure API call
[Gemini/OpenAI Vision API]
        ‚Üì Results
[Your Server] 
        ‚Üì JSON response
[Your App displays results]
</code></pre>
<h3 id="option-1-use-railway-recommended-free-tier-available_1">Option 1: Use Railway (Recommended - Free Tier Available)</h3>
<p><strong>Why Railway?</strong>
- ‚úÖ Free tier: $5 credit/month (enough for demos)
- ‚úÖ Easy deployment from GitHub
- ‚úÖ No credit card required for trial
- ‚úÖ Better than Vercel for Django/Flask
- ‚úÖ Automatic HTTPS</p>
<p><strong>Deployment Steps:</strong>
1. Push your Django code to GitHub
2. Go to railway.app
3. Click "Start a New Project" ‚Üí "Deploy from GitHub"
4. Select your repository
5. Railway auto-detects Django and deploys
6. Add environment variable: <code>GEMINI_API_KEY</code>
7. Get your public URL: <code>https://yourapp.railway.app</code></p>
<p><strong>In Adalo/Softr:</strong></p>
<pre><code>API Endpoint: https://yourapp.railway.app/analyze
Method: POST
Body: {&quot;image_url&quot;: &quot;https://...&quot;}
Headers: {&quot;Content-Type&quot;: &quot;application/json&quot;}
</code></pre>
<h3 id="option-2-use-render-also-free-tier_1">Option 2: Use Render (Also Free Tier)</h3>
<p><strong>Why Render?</strong>
- ‚úÖ Free tier (no credit card needed)
- ‚úÖ Simple setup
- ‚úÖ Good documentation
- ‚úÖ Auto-deploy from GitHub</p>
<p><strong>Deployment Steps:</strong>
1. Push code to GitHub
2. Go to render.com
3. New ‚Üí Web Service
4. Connect GitHub repository
5. Render auto-builds
6. Add environment variable: <code>GEMINI_API_KEY</code>
7. Get URL: <code>https://yourapp.onrender.com</code></p>
<p><strong>Note:</strong> Free tier sleeps after 15 min inactivity (first request takes ~30 sec to wake up)</p>
<h3 id="option-3-use-pythonanywhere-beginner-friendly_1">Option 3: Use PythonAnywhere (Beginner-Friendly)</h3>
<p><strong>Why PythonAnywhere?</strong>
- ‚úÖ Forever free tier
- ‚úÖ No credit card required
- ‚úÖ Web-based file editor
- ‚úÖ Good for learning</p>
<p><strong>Deployment Steps:</strong>
1. Sign up at pythonanywhere.com (free)
2. Open a Bash console
3. Clone your repo: <code>git clone https://github.com/yourusername/yourrepo</code>
4. Set up virtual environment
5. Configure web app in "Web" tab
6. Set environment variables in "Web" tab
7. URL: <code>https://yourusername.pythonanywhere.com</code></p>
<p><strong>Limitations:</strong> No automatic GitHub deployments on free tier</p>
<h3 id="how-to-connect-from-adalo_1">How to Connect from Adalo</h3>
<p><strong>Step 1: Create API Endpoint in Your App</strong>
Your Django view should accept POST requests:</p>
<pre><code class="language-python"># views.py
def analyze_image_api(request):
    if request.method == 'POST':
        image_url = request.POST.get('image_url')
        # Process with Gemini API
        result = analyze_image(image_url)
        return JsonResponse({'result': result})
</code></pre>
<p><strong>Step 2: In Adalo</strong>
1. Add "Custom Action" to your button
2. Method: POST
3. URL: <code>https://yourapp.railway.app/api/analyze</code>
4. Body: </p>
<pre><code class="language-json">{
  &quot;image_url&quot;: &quot;{{ImageComponent.URL}}&quot;
}
</code></pre>
<ol>
<li>Save response as a variable</li>
<li>Display in Text component: <code>{{APIResponse.result}}</code></li>
</ol>
<p><strong>Limitations:</strong> Adalo free tier may have API call restrictions</p>
<h3 id="how-to-connect-from-softr_1">How to Connect from Softr</h3>
<p><strong>Step 1: Use Airtable as Bridge</strong>
Softr works best with Airtable. Strategy:
1. User uploads image to Softr form ‚Üí saves to Airtable
2. Airtable Automation triggers when new record created
3. Automation calls your Railway/Render API via Webhook
4. API analyzes image and returns result
5. Automation updates Airtable record with result
6. Softr displays the updated record</p>
<p><strong>Step 2: Airtable Automation Setup</strong>
1. In Airtable: Create automation
2. Trigger: "When record created"
3. Action: "Send webhook"
4. Webhook URL: <code>https://yourapp.railway.app/api/analyze</code>
5. Method: POST
6. Body: <code>{"image_url": "{{Image URL from record}}"}</code>
7. Parse response and update same record</p>
<h3 id="how-to-connect-from-boltnew_1">How to Connect from Bolt.new</h3>
<p><strong>Option A: Bolt.new Already Has Backend Capabilities</strong>
Bolt.new generates full-stack code, so you can add API calls directly:</p>
<ol>
<li>Ask Bolt: "Add a backend API route that accepts image uploads and calls Gemini API"</li>
<li>Bolt generates both frontend and backend</li>
<li>Deploy the entire app to Railway/Render</li>
<li>No separate server needed!</li>
</ol>
<p><strong>Option B: Call External API</strong>
If you built the Django app separately:</p>
<pre><code class="language-javascript">// In Bolt.new generated code
async function analyzeImage(imageFile) {
  const formData = new FormData();
  formData.append('image', imageFile);

  const response = await fetch('https://yourapp.railway.app/api/analyze', {
    method: 'POST',
    body: formData
  });

  const result = await response.json();
  return result;
}
</code></pre>
<h3 id="security-considerations_1">Security Considerations</h3>
<p><strong>‚ùå NEVER Do This:</strong></p>
<pre><code class="language-javascript">// DON'T put API keys in frontend code!
const apiKey = &quot;AIzaSy...&quot;; // ‚Üê Visible to everyone!
</code></pre>
<p><strong>‚úÖ ALWAYS Do This:</strong></p>
<pre><code class="language-python"># Django backend - API key is safe on server
api_key = os.getenv('GEMINI_API_KEY')  # ‚Üê Only visible on server
</code></pre>
<h3 id="free-tier-comparison_1">Free Tier Comparison</h3>
<table>
<thead>
<tr>
<th>Service</th>
<th>Free Tier</th>
<th>Requires Card?</th>
<th>Best For</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Railway</strong></td>
<td>$5 credit/month</td>
<td>No (trial)</td>
<td>Django, Flask, Quick deploys</td>
</tr>
<tr>
<td><strong>Render</strong></td>
<td>750 hours/month</td>
<td>No</td>
<td>Simple apps, auto-deploy</td>
</tr>
<tr>
<td><strong>PythonAnywhere</strong></td>
<td>Forever free</td>
<td>No</td>
<td>Learning, permanent hosting</td>
</tr>
<tr>
<td><strong>Vercel</strong></td>
<td>Good for Next.js</td>
<td>No</td>
<td>NOT recommended for Django</td>
</tr>
<tr>
<td><strong>Netlify</strong></td>
<td>Static sites only</td>
<td>No</td>
<td>NOT for backend APIs</td>
</tr>
</tbody>
</table>
<h3 id="high-level-integration-summary_1">High-Level Integration Summary</h3>
<p><strong>What You Need:</strong>
1. ‚úÖ Your Django app with API endpoint (already built in workshop)
2. ‚úÖ Free hosting account (Railway or Render)
3. ‚úÖ GitHub repository
4. ‚úÖ 10 minutes to deploy</p>
<p><strong>What Your No-Code Tool Needs:</strong>
- <strong>Adalo</strong>: Custom action with POST request
- <strong>Softr</strong>: Airtable automation webhook
- <strong>Bolt.new</strong>: Fetch API call in generated code</p>
<p><strong>Result:</strong></p>
<pre><code>User uploads image in Adalo/Softr/Bolt
    ‚Üì
Your server analyzes it with Gemini
    ‚Üì
Results display in your app
</code></pre>
<h3 id="troubleshooting-common-issues_1">Troubleshooting Common Issues</h3>
<p><strong>Issue: "CORS Error"</strong>
‚Üí Add CORS headers to your Django app:</p>
<pre><code class="language-python"># settings.py
CORS_ALLOW_ALL_ORIGINS = True  # For development
</code></pre>
<p><strong>Issue: "API key not found"</strong>
‚Üí Check environment variables are set in Railway/Render dashboard</p>
<p><strong>Issue: "Request timeout"</strong>
‚Üí Render free tier sleeps. First request takes 30 sec. Warn users to wait.</p>
<p><strong>Issue: "Too expensive"</strong>
‚Üí Use Railway's free $5/month. Set up usage alerts. Should be enough for 100-500 requests.</p>
<h3 id="workshop-recommendation_1">Workshop Recommendation</h3>
<p><strong>For Today's Demo:</strong>
Focus on building the Django app locally. Explain that deploying to Railway/Render is optional for Week 11 projects.</p>
<p><strong>For Week 11 Projects:</strong>
Students who want to integrate with Adalo/Softr should:
1. Deploy their Django backend to Railway (free tier)
2. Follow the integration guide for their specific tool
3. Test with 5-10 images first (to avoid running out of free credits)</p>
<hr />
<h2 id="additional-resources_1">üìö Additional Resources</h2>
<h3 id="official-documentation_1">Official Documentation</h3>
<ul>
<li>Google Gemini API: https://ai.google.dev/</li>
<li>OpenAI Vision API: https://platform.openai.com/docs/guides/vision</li>
<li>Django Documentation: https://docs.djangoproject.com/</li>
</ul>
<h3 id="learning-prompt-engineering_1">Learning Prompt Engineering</h3>
<ul>
<li>Anthropic's Prompt Engineering Guide: https://docs.anthropic.com/prompt-engineering</li>
<li>OpenAI Prompt Engineering Guide: https://platform.openai.com/docs/guides/prompt-engineering</li>
</ul>
<hr />
<h2 id="workshop-challenge_1">üéØ Workshop Challenge</h2>
<p><strong>Try this after the demo:</strong></p>
<p>Use the prompts in this guide to build YOUR OWN version of the image analysis app, but customize it for YOUR Week 11 project idea.</p>
<ol>
<li>Start with the main prompt</li>
<li>Modify the system prompt to fit your use case</li>
<li>Add 1-2 features using the iteration prompts</li>
<li>Share what you built with your team!</li>
</ol>
<p>Remember: The best way to learn is by doing. Don't just watch - code along!</p>
<hr />
<p><strong>Questions?</strong> Ask during the workshop or experiment on your own. The worst that can happen is you learn what NOT to do! üòä</p>
        <hr>
        <a href="index.html" class="back-button">‚Üê Back to Workshop Home</a>
    </div>
</body>
</html>
